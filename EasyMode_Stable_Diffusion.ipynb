{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravinda89/generative_art/blob/main/EasyMode_Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Q7lggNI5DEPX",
        "outputId": "e762ddbb-d61f-4a2d-de42-53705d2fb0e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "  li img, p img {vertical-align: middle;}\n",
              "  .overview {font-size: 16px;}\n",
              "  .markdown :not(pre)>code {\n",
              "    background-color: #1e1e1e;\n",
              "    border-radius: 2px;\n",
              "    padding: 2px 5px;\n",
              "  }\n",
              "  .markdown code {\n",
              "      font-size: 90%;\n",
              "      color: white;\n",
              "  }\n",
              "</style>\n",
              "<body>\n",
              "<div class=\"markdown overview\">\n",
              "<p>With this Google Colab, you can train an AI text-to-image generator called <a href=\"https://en.wikipedia.org/wiki/Stable_Diffusion\" target=\"_blank\" rel=\"nofollow\">Stable Diffusion</a> to generate images that resemble the photos you provide as input</p>\n",
              "<p>To run a step, press the  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> and wait for it to finish. You will see a  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920487-aa67d823-7424-4613-b62d-74d4a4b4fb29.png\" alt=\"colab-check\"> on the left side of <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920376-2b18380b-f879-4326-bce6-8ac70fe3744b.png\" alt=\"play\"> when it is complete. Proceed to the next step. Steps 1-3 must be completed before using steps 4-5</p>\n",
              "<ol>\n",
              "<li>Setup - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> </li>\n",
              "<li>Upload - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> then <img src=\"https://user-images.githubusercontent.com/507464/210199321-28a6c380-1044-423f-a111-3ed96e5a8eb1.png\" alt=\"choose-files\"> will show. Start uploading your photos.</li>\n",
              "<li>Train - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will take around ~30 minutes to complete.</li>\n",
              "<li>Generate - Change <code>PROMPT</code> and other desired settings then press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. You can repeat this step as many times as you want without rerunning steps 1-3</li>\n",
              "<li>Save -  Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will save model to Google Drive, you must have at least 2GB free space to continue.</li>\n",
              "</ol>\n",
              "<p>This Colab is based on <a href=\"https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth\" target=\"_blank\" rel=\"nofollow\">ShivamShrirao's repository</a> and has been modified by <img src=\"https://user-images.githubusercontent.com/507464/213915305-35c7227c-639d-4480-b521-bd89ba6b0d09.png\" alt=\"youtube\"> <a href=\"https://github.com/geocine/sd-easy-mode\" target=\"_blank\" rel=\"nofollow\">geocine</a> to be more accessible to complete beginners. It is not intended for advanced or long-term use.</p>\n",
              "<p>You can watch <img src=\"https://user-images.githubusercontent.com/507464/213915097-b3d8450a-1011-4923-8782-867124b0c7a8.png\" alt=\"youtube\"> <a href=\"https://www.youtube.com/watch?v=HVOvL2CyBT0\" target=\"_blank\">this video</a> by <b>Nolan Aatama</b> on youtube to see how it works!</p>\n",
              "</span></div>\n",
              "</body>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown # Instructions\n",
        "%%html\n",
        "<style>\n",
        "  li img, p img {vertical-align: middle;}\n",
        "  .overview {font-size: 16px;}\n",
        "  .markdown :not(pre)>code {\n",
        "    background-color: #1e1e1e;\n",
        "    border-radius: 2px;\n",
        "    padding: 2px 5px;\n",
        "  }\n",
        "  .markdown code {\n",
        "      font-size: 90%;\n",
        "      color: white;\n",
        "  }\n",
        "</style>\n",
        "<body>\n",
        "<div class=\"markdown overview\">\n",
        "<p>With this Google Colab, you can train an AI text-to-image generator called <a href=\"https://en.wikipedia.org/wiki/Stable_Diffusion\" target=\"_blank\" rel=\"nofollow\">Stable Diffusion</a> to generate images that resemble the photos you provide as input</p>\n",
        "<p>To run a step, press the  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> and wait for it to finish. You will see a  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920487-aa67d823-7424-4613-b62d-74d4a4b4fb29.png\" alt=\"colab-check\"> on the left side of <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920376-2b18380b-f879-4326-bce6-8ac70fe3744b.png\" alt=\"play\"> when it is complete. Proceed to the next step. Steps 1-3 must be completed before using steps 4-5</p>\n",
        "<ol>\n",
        "<li>Setup - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> </li>\n",
        "<li>Upload - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> then <img src=\"https://user-images.githubusercontent.com/507464/210199321-28a6c380-1044-423f-a111-3ed96e5a8eb1.png\" alt=\"choose-files\"> will show. Start uploading your photos.</li>\n",
        "<li>Train - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will take around ~30 minutes to complete.</li>\n",
        "<li>Generate - Change <code>PROMPT</code> and other desired settings then press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. You can repeat this step as many times as you want without rerunning steps 1-3</li>\n",
        "<li>Save -  Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will save model to Google Drive, you must have at least 2GB free space to continue.</li>\n",
        "</ol>\n",
        "<p>This Colab is based on <a href=\"https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth\" target=\"_blank\" rel=\"nofollow\">ShivamShrirao's repository</a> and has been modified by <img src=\"https://user-images.githubusercontent.com/507464/213915305-35c7227c-639d-4480-b521-bd89ba6b0d09.png\" alt=\"youtube\"> <a href=\"https://github.com/geocine/sd-easy-mode\" target=\"_blank\" rel=\"nofollow\">geocine</a> to be more accessible to complete beginners. It is not intended for advanced or long-term use.</p>\n",
        "<p>You can watch <img src=\"https://user-images.githubusercontent.com/507464/213915097-b3d8450a-1011-4923-8782-867124b0c7a8.png\" alt=\"youtube\"> <a href=\"https://www.youtube.com/watch?v=HVOvL2CyBT0\" target=\"_blank\">this video</a> by <b>Nolan Aatama</b> on Youtube to see how it works!</p>\n",
        "</span></div>\n",
        "</body>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aLWXPZqjsZVV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "62df023dc06d490c8788bbe84eb1fd49",
            "5eafb166bc744319a944305f8b235898",
            "0e195f411c36490dab5d31e801346aa8",
            "110a8d110bd64a27ba4bce011d5af3a4",
            "6c0dc57af07848a897b11f145d70127e",
            "a56027d7b2dd40539c6ea20a7d5df2d6",
            "1567ef9e7ab24c5aac73612463ea7ac9",
            "019861e9b52d4316bceb03156954654c",
            "4f70b00991be436f94b629cf820dfec2",
            "58eff1fb33d949bd8e80ea0f24b3c45c",
            "0a00fc369d534ae0bb51998253ea2d73"
          ]
        },
        "outputId": "84ec9024-8ec9-48da-f6d5-b1171122dc0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4, Total VRAM: 15360 MB, Free VRAM: 15109 MB\n",
            "\u001b[92mYou have enough VRAM to continue\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(HTML(value='Installing: 0%'), IntProgress(value=0, max=7), HTML(value='', layout=Layout(margin=…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62df023dc06d490c8788bbe84eb1fd49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mInstallation complete\u001b[0m\n",
            "[*] Models will be saved at /content/stable_diffusion_models/zwx\n"
          ]
        }
      ],
      "source": [
        "# You may change these settings if you know what you are doing\n",
        "BRANCH = \"main\" # Branch/Tag of the repository to use\n",
        "SDD_TOKEN = \"zwx\" # Token name for this subject, If you decide to change this later, you can just rerun this cell without any issues\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" # Base model you want to use, only diffusers model\n",
        "\n",
        "!wget -q -O easymode.py https://github.com/geocine/sd-easy-mode/raw/{BRANCH}/easymode.py\n",
        "!rm -rf /content/sample_data\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "from google.colab import output\n",
        "import warnings\n",
        "import time\n",
        "from easymode import ProgressBar, install_package, replace_tokens, download_regularization, print_message\n",
        "\n",
        "\n",
        "# Your JSON data\n",
        "concepts_list_data =   {\n",
        "    \"instance_prompt\": \"photo of {SDD_TOKEN} {SDD_CLASS}\",\n",
        "    \"class_prompt\": \"photo of {SDD_CLASS}\",\n",
        "    \"instance_data_dir\": \"/content/data/training_images\",\n",
        "    \"class_data_dir\": \"/content/data/{SDD_CLASS}\"\n",
        "}\n",
        "# Replace {SDD_TOKEN} with a SDD_TOKEN\n",
        "concepts_list_data[\"instance_prompt\"] = concepts_list_data[\"instance_prompt\"].replace(\"{SDD_TOKEN}\", SDD_TOKEN)\n",
        "concepts_list_data[\"instance_data_dir\"] = concepts_list_data[\"instance_data_dir\"].replace(\"{SDD_TOKEN}\", SDD_TOKEN)\n",
        "\n",
        "# Write the data to a file with proper indentation\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump([concepts_list_data], f, indent=2)\n",
        "\n",
        "# Disable the warning message\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning,\n",
        "                        module=\"IPython.core.interactiveshell\")\n",
        "\n",
        "# GPU Check\n",
        "\n",
        "# @markdown The system checks for a compatible GPU with enough memory and installs necessary Python packages during setup.\n",
        "# Run the nvidia-smi command to get the VRAM information\n",
        "result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,memory.total,memory.free\",\n",
        "                        \"--format=csv,noheader\"], capture_output=True, check=True)\n",
        "\n",
        "# Split the output by newline characters to get a list of VRAM info for each GPU\n",
        "vram_info = result.stdout.decode(\"utf-8\").strip().split(\"\\n\")\n",
        "\n",
        "# Parse the VRAM info for each GPU\n",
        "for info in vram_info:\n",
        "    name, total, free = info.split(\",\")\n",
        "    total = int(total.strip().split()[0])  # Total VRAM in MB\n",
        "    free = int(free.strip().split()[0])  # Free VRAM in MB\n",
        "\n",
        "    print(f\"GPU: {name}, Total VRAM: {total} MB, Free VRAM: {free} MB\")\n",
        "\n",
        "if total < 15109:  # 15109MB is equivalent to 15GB\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[91mError: Not enough VRAM available. Please change the runtime to a GPU with at least 15GB VRAM.\\033[0m\")\n",
        "    raise SystemExit\n",
        "else:\n",
        "    print(\"\\033[92mYou have enough VRAM to continue\\033[0m\")\n",
        "\n",
        "# Installation\n",
        "\n",
        "!wget -q -O train_dreambooth.py https://github.com/geocine/sd-easy-mode/raw/{BRANCH}/train_dreambooth.py\n",
        "!wget -q -O convert_diffusers_to_original_stable_diffusion.py https://github.com/geocine/sd-easy-mode/raw/{BRANCH}/convert_diffusers_to_original_stable_diffusion.py\n",
        "\n",
        "# URLs of the diffusers and xformers packages\n",
        "DIFFUSERS_URL = 'git+https://github.com/ShivamShrirao/diffusers'\n",
        "XFORMERS_URL = 'https://github.com/geocine/dreamstall-binaries/releases/download/cxx-p38-txx-linux/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl'\n",
        "\n",
        "# List of packages to check and install\n",
        "packages = ['diffusers', 'triton', 'accelerate==0.12.0',\n",
        "            'transformers', 'ftfy', 'bitsandbytes==0.35.0', 'xformers']\n",
        "\n",
        "# Check and install each package\n",
        "pb = ProgressBar(len(packages), \"Installing\")\n",
        "for package in packages:\n",
        "    label = install_package(package, DIFFUSERS_URL, XFORMERS_URL, \"exp\", False)\n",
        "    pb.update(label)\n",
        "print(\"\\033[92mInstallation complete\\033[0m\")\n",
        "\n",
        "!mkdir -p ~/.cache/huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\"\n",
        "\n",
        "# check if HUGGINGFACE_TOKEN is set\n",
        "if not HUGGINGFACE_TOKEN:\n",
        "    # Display an error message in red text\n",
        "    print_message(\"warning\", \"Please set HUGGINGFACE_TOKEN first.\")\n",
        "\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.cache/huggingface/token\n",
        "\n",
        "OUTPUT_DIR = f\"stable_diffusion_models/{SDD_TOKEN}\"\n",
        "OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(\"config.json\", \"w\") as f:\n",
        "    # Write the data to the file in indent format\n",
        "    json.dump({\"model_name\": MODEL_NAME, \"output_dir\": OUTPUT_DIR}, f, indent=4)\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    # Remove all files and directories inside the directory using the rm command\n",
        "    subprocess.run([\"rm\", \"-rf\", f\"{OUTPUT_DIR}/*\"], check=True)\n",
        "else:\n",
        "    # Create the directory\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "print(f\"[*] Models will be saved at {OUTPUT_DIR}\")\n",
        "os.makedirs(\"/content/data/training_images\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W530tWf904D"
      },
      "source": [
        "# Upload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "ca46bda3-fd96-40ae-b19c-81104e9c1ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading instance images for `photo of zwx `\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-90c72d3c-e95a-44b8-a7f8-f5c68d1a6ed4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-90c72d3c-e95a-44b8-a7f8-f5c68d1a6ed4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 0_Hayley-Atwell-1411203.jpg to 0_Hayley-Atwell-1411203.jpg\n",
            "Saving conviction-hayley-atwell-poster-jpg.webp to conviction-hayley-atwell-poster-jpg.webp\n",
            "Saving conviction-hayley-atwell.webp to conviction-hayley-atwell.webp\n",
            "Saving hayley-atwell-1-scaled.jpg to hayley-atwell-1-scaled.jpg\n",
            "Saving hayley-atwell-1669656673.jpg to hayley-atwell-1669656673.jpg\n",
            "Saving hayley-atwell-at-top-gun-premiere-tom-cruise-02.jpg to hayley-atwell-at-top-gun-premiere-tom-cruise-02.jpg\n",
            "Saving hayley-atwell-captain-america-v0-omss65lfr5x91.webp to hayley-atwell-captain-america-v0-omss65lfr5x91.webp\n",
            "Saving hayley-atwell-has-starred-in-tons-of-mcu-movies-1608308157.jpg to hayley-atwell-has-starred-in-tons-of-mcu-movies-1608308157.jpg\n",
            "Saving hayley-atwell-los-angeles-ca-march-world-premiere-her-movie-captain-america-winter-soldier-el-capitan-theatre-45218403.jpg to hayley-atwell-los-angeles-ca-march-world-premiere-her-movie-captain-america-winter-soldier-el-capitan-theatre-45218403.jpg\n",
            "Saving hayley-atwell.webp to hayley-atwell.webp\n",
            "Saving images.jpg to images.jpg\n",
            "Saving index.jpg to index.jpg\n",
            "Saving intro-1608308157.jpg to intro-1608308157.jpg\n",
            "Saving intro-1609365650.jpg to intro-1609365650.jpg\n",
            "Saving RT_HayleyAtwell.webp to RT_HayleyAtwell.webp\n",
            "Saving Telegraph_01_295v2_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwar5A7Xlc4wUDt-29537URE.jpg to Telegraph_01_295v2_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwar5A7Xlc4wUDt-29537URE.jpg\n",
            "Saving tihrCdH5TE3kgcdSCK2n4d.jpg to tihrCdH5TE3kgcdSCK2n4d.jpg\n",
            "\u001b[92mImages have been uploaded. If you need to add more, simply run this cell again\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# @markdown To train the model, run this cell to upload 15-20 images of your subject. The images should be 512x512 in size and show the subject in various poses, expressions, and backgrounds. The images should show the subject in different variations. If your images are not already 512x512, you can use [this tool](https://www.birme.net/?target_width=512&target_height=512) to resize them in a batch.<br><br>\n",
        "# @markdown You can also upload directly on the `/data/training_images` folder on the file explorer which is faster than using the upload button below.\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    print_message(\"warning\", \"Please run the Setup cell first\")\n",
        "\n",
        "replace_tokens(\"/content/concepts_list.json\", SDD_TOKEN)\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "# Incorporate this so that users won't have to crop their images https://github.com/d8ahazard/sd_smartprocess\n",
        "for c in concepts_list:\n",
        "    prompt = c['instance_prompt']\n",
        "    prompt = prompt.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=\"\")\n",
        "    print(f\"Uploading instance images for `{prompt}`\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "      print_message(\"error\",\"Please run the Upload step again and select the images you want to use\")\n",
        "    else:\n",
        "      for filename in uploaded.keys():\n",
        "          dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "          # Create the instance_data_dir directory if it does not exist\n",
        "          os.makedirs(c['instance_data_dir'], exist_ok=True)\n",
        "          shutil.move(filename, dst_path)\n",
        "\n",
        "print(\"\\033[92mImages have been uploaded. If you need to add more, simply run this cell again\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn5ILIyDJIcX"
      },
      "source": [
        "# Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650,
          "referenced_widgets": [
            "9386f75d13e7459bbc65e0e6a225c6fd",
            "6c4d39d95ed3418587525fd191585e96",
            "350798f012bd4dfebc6090be7e02b904",
            "bae28680287f4a7194d524eadfa32ab5",
            "856264b1ab3a475aa1fdc533f0d78daa",
            "e0b0acb2651d4a898f9da8313afce00e",
            "58018eef766944499a284c76398a5c41",
            "1599d7d484194378bf61ffdb6c86ac54",
            "b4966f6c1ae245898b23dadc8751e4d8",
            "1b7a0c169bf14607b6a5957a1e51642c",
            "4b2be930d2784fe2876a331d824ee071"
          ]
        },
        "outputId": "159295b5-9fc9-4b6e-ba25-265ba73fcdce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(HTML(value='Extracting: 0%'), IntProgress(value=0, max=2121), HTML(value='', layout=Layout(marg…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9386f75d13e7459bbc65e0e6a225c6fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mExtracting regularization images completed\u001b[0m\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 6.11MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 4.42MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 190kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 822/822 [00:00<00:00, 267kB/s]\n",
            "Downloading (…)_encoder/config.json: 100% 636/636 [00:00<00:00, 103kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 246M/246M [00:01<00:00, 135MB/s]\n",
            "Downloading (…)_pytorch_model.bin\";: 100% 167M/167M [00:01<00:00, 116MB/s]\n",
            "Downloading (…)fp16/vae/config.json: 100% 609/609 [00:00<00:00, 242kB/s]\n",
            "Downloading (…)_pytorch_model.bin\";: 100% 1.72G/1.72G [00:08<00:00, 196MB/s]\n",
            "Downloading (…)p16/unet/config.json: 100% 806/806 [00:00<00:00, 310kB/s]\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "CUDA SETUP: CUDA runtime path found: /usr/lib64-nvidia/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 112\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda112.so...\n",
            "Downloading (…)cheduler_config.json: 100% 308/308 [00:00<00:00, 78.0kB/s]\n",
            "Caching latents: 100% 170/170 [00:44<00:00,  3.79it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 170\n",
            "  Num batches each epoch = 170\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2532\n",
            "Steps:  34% 854/2532 [12:50<24:46,  1.13it/s, loss=0.291, lr=1e-6]"
          ]
        }
      ],
      "source": [
        "!cp /usr/local/cuda/lib64/libcudart.so /usr/lib64-nvidia\n",
        "\n",
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    print_message(\"warning\", \"Please run the Setup cell first\")\n",
        "\n",
        "from easymode import ProgressBar, create_interpolation_function, replace_tokens, download_regularization, print_message\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    data = json.load(f)[0]\n",
        "\n",
        "# Extract the SDD_TOKEN value from the \"instance_prompt\" field\n",
        "instance_prompt = data[\"instance_prompt\"]\n",
        "SDD_TOKEN = instance_prompt.split(\" \")[-2]\n",
        "\n",
        "# Extract the SDD_CLASS value from the \"class_data_dir\" field\n",
        "class_data_dir = data[\"class_data_dir\"]\n",
        "SDD_CLASS = class_data_dir.split(\"/\")[-1]\n",
        "\n",
        "# Open the file in read mode\n",
        "with open(\"/content/config.json\", \"r\") as f:\n",
        "    # Load the JSON data from the file\n",
        "    config = json.load(f)\n",
        "\n",
        "# Assign the value of the \"model_name\" property to the MODEL_NAME variable\n",
        "MODEL_NAME = config[\"model_name\"]\n",
        "OUTPUT_DIR = config[\"output_dir\"]\n",
        "\n",
        "os.environ['BITSANDBYTES_NOWELCOME'] = \"1\"\n",
        "# @markdown The number of steps is currently set to auto-compute(-1), but you can adjust them to try and improve accuracy. More steps usually improve accuracy, but too many can cause the model to overfit and perform poorly on other tasks like styling. Fewer steps may result in less accurate models. Only change these settings if you understand the potential consequences and are familiar with the process. If you do adjust the number of steps, make small changes and test the model's performance.\n",
        "\n",
        "MAX_TRAIN_STEPS = -1  # @param {type:\"number\"}\n",
        "SDD_CLASS = \"person\" #@param [\"person\", \"man\", \"woman\", \"dog\", \"cat\", \"artstyle\"]\n",
        "SAVE_SAMPLE_PROMPT = \"photo of {TOKEN_CLASS}\"\n",
        "SAVE_SAMPLE_PROMPT = SAVE_SAMPLE_PROMPT.format(\n",
        "    TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "\n",
        "# @markdown `SDD_CLASS` is the subject type you want to train.<br><br>\n",
        "# @markdown The default value for `SDD_CLASS` is `person`. For example, if you set `SDD_CLASS` to `dog` then use the prompt `zwx dog` on the **Generate** step.\n",
        "\n",
        "replace_tokens(\"/content/concepts_list.json\", SDD_TOKEN, SDD_CLASS)\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "num_images = 0\n",
        "\n",
        "c = concepts_list[0]\n",
        "data_dir = c['instance_data_dir']\n",
        "# replace the SDD_TOKEN placeholders with the actual values\n",
        "data_dir = data_dir.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=\"\")\n",
        "# Check if the directory exists\n",
        "if os.path.exists(data_dir):\n",
        "    # Check if the directory is empty\n",
        "    num_files = len(os.listdir(data_dir))\n",
        "    if num_files == 0:\n",
        "        print_message(\"error\", f\"The directory `{data_dir}` is empty. Please upload some images using the Upload step above.\")\n",
        "    else:\n",
        "        num_images += num_files\n",
        "else:\n",
        "    # Raise an exception if the directory does not exist\n",
        "    print_message(\"error\", f\"The directory `{data_dir}` does not exist. Please run the Upload cell first\")\n",
        "# interpolation computation based on Astria results\n",
        "interpolate_max_train_steps = create_interpolation_function(\n",
        "    [(10, 1611), (11, 1750), (15, 2281)])\n",
        "\n",
        "\n",
        "# You may change these settings if you know what you are doing\n",
        "\n",
        "NUM_CLASS_IMAGES = num_images * 10\n",
        "if MAX_TRAIN_STEPS < 0:\n",
        "    MAX_TRAIN_STEPS = int(interpolate_max_train_steps(num_images))\n",
        "\n",
        "regularizations = [SDD_CLASS]\n",
        "\n",
        "for regularization in regularizations:\n",
        "    download_regularization(regularization)\n",
        "\n",
        "SAVE_INTERVAL = 10000\n",
        "SAVE_MIN_STEPS = 0\n",
        "CLEAR_MODELS = True\n",
        "SAMPLE_BATCH_SIZE = 4\n",
        "\n",
        "\n",
        "# Check SAVE_MIN_STEPS should be should be less than or equal MAX_TRAIN_STEPS\n",
        "if SAVE_MIN_STEPS > MAX_TRAIN_STEPS:\n",
        "    print_message(\"error\", \"Your model will not be saved if SAVE_MIN_STEPS is greater than MAX_TRAIN_STEPS.\")\n",
        "\n",
        "PRE_GENERATE = None\n",
        "g_cuda = None\n",
        "\n",
        "# Write the data to a file with proper indentation\n",
        "with open(\"settings.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"num_class_images\": NUM_CLASS_IMAGES,\n",
        "        \"sample_batch_size\": SAMPLE_BATCH_SIZE,\n",
        "        \"max_train_steps\": MAX_TRAIN_STEPS,\n",
        "        \"save_interval\": SAVE_INTERVAL,\n",
        "        \"save_min_steps\": SAVE_MIN_STEPS,\n",
        "        \"save_sample_prompt\": SAVE_SAMPLE_PROMPT\n",
        "    }, f, indent=2)\n",
        "\n",
        "if CLEAR_MODELS:\n",
        "    # Run the rm command using subprocess\n",
        "    subprocess.run(\n",
        "        [\"rm\", \"-rf\", f\"/content/stable_diffusion_models/*\"])\n",
        "\n",
        "!accelerate launch --num_processes=1 --num_machines=1 --mixed_precision=\"no\" --num_cpu_threads_per_process=1 train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "    --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "    --output_dir=$OUTPUT_DIR \\\n",
        "    --revision=\"fp16\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --train_text_encoder \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --num_class_images=$NUM_CLASS_IMAGES \\\n",
        "    --sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
        "    --max_train_steps=$MAX_TRAIN_STEPS \\\n",
        "    --save_interval=$SAVE_INTERVAL \\\n",
        "    --save_min_steps=$SAVE_MIN_STEPS \\\n",
        "    --save_sample_prompt=\"$SAVE_SAMPLE_PROMPT\" \\\n",
        "    --concepts_list=\"concepts_list.json\"\n",
        "#   --shuffle_after_epoch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "# Generate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# @markdown The default value for `SDD_CLASS` is `person`. If you trained a different class, update the prompts accordingly. For example, if you set `SDD_CLASS` to `dog` then replace `zwx {SDD_CLASS}` with `zwx dog`.<br><br>\n",
        "# @markdown To generate images, change the parameters and run the cell. Include `zwx {SDD_CLASS}` in your prompts. For example: `a photo of zwx {SDD_CLASS}`. If you want more prompt ideas, you can check out [Astria's gallery](https://www.astria.ai/gallery) and replace `sks|zwx person|man|woman` with `zwx {SDD_CLASS}`.<br><br>\n",
        "\n",
        "if not os.path.exists(f'/content/settings.json') or not os.path.exists(f'/content/concepts_list.json'):\n",
        "    print_message(\"error\", \"Please run the Setup step above.\")\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "import random\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, EulerAncestralDiscreteScheduler\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"concepts_list.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the SDD_TOKEN value from the \"instance_prompt\" field\n",
        "instance_prompt = data[0][\"instance_prompt\"]\n",
        "SDD_TOKEN = instance_prompt.split(\" \")[-2]\n",
        "\n",
        "# Extract the SDD_CLASS value from the \"class_data_dir\" field\n",
        "class_data_dir = data[0][\"class_data_dir\"]\n",
        "SDD_CLASS = class_data_dir.split(\"/\")[-1]\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"settings.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Assign the value of MAX_TRAIN_STEPS from the JSON data to the MAX_TRAIN_STEPS variable\n",
        "MAX_TRAIN_STEPS = data[\"max_train_steps\"]\n",
        "MODEL_STEPS = MAX_TRAIN_STEPS\n",
        "\n",
        "if not os.path.exists(f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'):\n",
        "    print_message(\"error\", f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training step above.\")\n",
        "\n",
        "if 'PRE_GENERATE' not in globals():\n",
        "    PRE_GENERATE = None;\n",
        "\n",
        "if PRE_GENERATE is None or g_cuda is None:\n",
        "    print(\"Loading model...\")\n",
        "    PRE_GENERATE = False\n",
        "    # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "    model_path = f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'\n",
        "    model_path = model_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "    scheduler = EulerAncestralDiscreteScheduler(\n",
        "        num_train_timesteps=1000, beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(model_path):\n",
        "    print_message(\"error\", f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training step above.\")\n",
        "\n",
        "SEED = -1\n",
        "if (SEED < 0):\n",
        "    SEED = random.randint(0, 2**32 - 1)\n",
        "g_cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "PROMPT = \"closeup photo of zwx person, trending on artstation, by greg rutkowski, alphonse mucha\" # @param {type:\"string\"}\n",
        "PROMPT = PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\") \n",
        "NEGATIVE_PROMPT = \"ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, cloned face, disfigured, out of frame, extra limbs, bad anatomy, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, mutated hands, fused fingers, too many fingers, long neck, text, letters, signature, web address, copyright name, username, error, extra digit, fewer digits, loadscreen, grid, stock image, a stock photo, promo poster, fat\" # @param {type:\"string\"}\n",
        "NUM_IMAGES_PER_PROMPT = 4  # @param {type:\"number\"}\n",
        "GUIDANCE_SCALE = 7.5  # @param {type:\"number\"}\n",
        "INFERENCE_STEPS = 50  # @param {type:\"number\"}\n",
        "height = 512\n",
        "width = 512\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt=PROMPT,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        num_images_per_prompt=NUM_IMAGES_PER_PROMPT,\n",
        "        num_inference_steps=INFERENCE_STEPS,\n",
        "        guidance_scale=GUIDANCE_SCALE,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "text = \"\"\"\n",
        "<br>\n",
        "If you're not happy with the output, you can try adjusting the <code>GUIDANCE_SCALE</code> and <code>INFERENCE_STEPS</code> parameters to improve the accuracy and quality of the generated images. \n",
        "<br><br>\n",
        "If the model is not generating a likeness, try using higher quality reference photos or increasing the number of training steps, then starting the training process again.\n",
        "<br>\n",
        "<br>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(text))\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EydphztWBiI"
      },
      "source": [
        "# Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hHvppaFtcFA4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "if not os.path.exists(f'/content/settings.json') or not os.path.exists(f'/content/concepts_list.json'):\n",
        "    print_message(\"error\", \"Please run the Setup step above.\")\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"concepts_list.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the SDD_TOKEN value from the \"instance_prompt\" field\n",
        "instance_prompt = data[0][\"instance_prompt\"]\n",
        "SDD_TOKEN = instance_prompt.split(\" \")[-2]\n",
        "\n",
        "# Extract the SDD_CLASS value from the \"class_data_dir\" field\n",
        "class_data_dir = data[0][\"class_data_dir\"]\n",
        "SDD_CLASS = class_data_dir.split(\"/\")[-1]\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"settings.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Assign the value of MAX_TRAIN_STEPS from the JSON data to the MAX_TRAIN_STEPS variable\n",
        "MAX_TRAIN_STEPS = data[\"max_train_steps\"]\n",
        "\n",
        "# @markdown This will save your trained model to your Google Drive. <font color=\"#1f76b6\" >Make sure you have 2GB free space</font>. You can then download it and use it offline with the desktop application [Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui). Please join [Stable Diffusion Dreambooth Discord](https://discord.com/invite/qbMuXBXyHA), we have a helpful community.<br><br>\n",
        "# @markdown **Note:** <font color=\"#1f76b6\" >If Google Colab crashes after running this, just run it again and it should succeed.</span>\n",
        "MODEL_STEPS = MAX_TRAIN_STEPS\n",
        "mdl_path = f\"/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}\"\n",
        "mdl_path = mdl_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "ckpt_path = mdl_path + \"/model.ckpt\"\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(mdl_path):\n",
        "    print_message(\"error\", f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training step above.\")\n",
        "\n",
        "if not os.path.exists(ckpt_path):\n",
        "    !python convert_diffusers_to_original_stable_diffusion.py --model_path $mdl_path --checkpoint_path $ckpt_path --half\n",
        "    print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n",
        "\n",
        "# Check if Google Drive is already mounted\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    # Mount Google Drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "NAME = \"me\"  # @param {type:\"string\"}\n",
        "# @markdown Enter the path to save the model in Google Drive. If left empty, the model will be saved in the root of Google Drive.\n",
        "GDRIVE_PATH = \"\"  # @param {type:\"string\"}\n",
        "# @markdown <font color=\"#1f76b6\" >It will take some time to appear on Google Drive, wait for 5 minutes</font>\n",
        "# remove / from start and end of GDRIVE_PATH if they exist\n",
        "GDRIVE_PATH = GDRIVE_PATH.strip('/')\n",
        "MODEL_NAME = f\"{NAME}-{SDD_CLASS}-{MODEL_STEPS}-{SDD_TOKEN}\"\n",
        "if GDRIVE_PATH:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{GDRIVE_PATH}/{MODEL_NAME}.ckpt\"\n",
        "else:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{MODEL_NAME}.ckpt\"\n",
        "\n",
        "# Execute the command\n",
        "!{cmd}\n",
        "if GDRIVE_PATH:\n",
        "    print(\n",
        "        f\"Model saved at /{GDRIVE_PATH}/{MODEL_NAME}.ckpt Wait for 5 minutes before closing\")\n",
        "else:\n",
        "    print(\n",
        "        f\"Model saved at /{MODEL_NAME}.ckpt Wait for 5 minutes before closing\")\n",
        "\n",
        "print(\n",
        "    f\"To use your model on other applications make sure to mention \\\"{SDD_TOKEN} {SDD_CLASS}\\\" in the prompt.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3L4EhLn4Cb8"
      },
      "source": [
        "Here are some resources you may find helpful as you continue learning about Stable Diffusion Dreambooth:\n",
        "\n",
        "- [The guide to fine-tuning Stable Diffusion with your own images](https://tryolabs.com/blog/2022/10/25/the-guide-to-fine-tuning-stable-diffusion-with-your-own-images)\n",
        "- [Basic Dreambooth Guide](https://github.com/nitrosocke/dreambooth-training-guide)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y213v6IvcUvk"
      },
      "outputs": [],
      "source": [
        "#@title Free runtime memory\n",
        "#@markdown If your session is running low on memory, you can run this cell. This will refresh your session and save your current work.\n",
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ST",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:18:13) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "94adf441e4abda7873a0f7f8d10896673bf8eb743389c6db05f684353e1dc292"
      }
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62df023dc06d490c8788bbe84eb1fd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eafb166bc744319a944305f8b235898",
              "IPY_MODEL_0e195f411c36490dab5d31e801346aa8",
              "IPY_MODEL_110a8d110bd64a27ba4bce011d5af3a4"
            ],
            "layout": "IPY_MODEL_6c0dc57af07848a897b11f145d70127e"
          }
        },
        "5eafb166bc744319a944305f8b235898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a56027d7b2dd40539c6ea20a7d5df2d6",
            "placeholder": "​",
            "style": "IPY_MODEL_1567ef9e7ab24c5aac73612463ea7ac9",
            "value": "Installing: 100%"
          }
        },
        "0e195f411c36490dab5d31e801346aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019861e9b52d4316bceb03156954654c",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f70b00991be436f94b629cf820dfec2",
            "value": 7
          }
        },
        "110a8d110bd64a27ba4bce011d5af3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58eff1fb33d949bd8e80ea0f24b3c45c",
            "placeholder": "​",
            "style": "IPY_MODEL_0a00fc369d534ae0bb51998253ea2d73",
            "value": "xformers is installed"
          }
        },
        "6c0dc57af07848a897b11f145d70127e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a56027d7b2dd40539c6ea20a7d5df2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1567ef9e7ab24c5aac73612463ea7ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019861e9b52d4316bceb03156954654c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f70b00991be436f94b629cf820dfec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58eff1fb33d949bd8e80ea0f24b3c45c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "2px 0 0 10px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a00fc369d534ae0bb51998253ea2d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9386f75d13e7459bbc65e0e6a225c6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c4d39d95ed3418587525fd191585e96",
              "IPY_MODEL_350798f012bd4dfebc6090be7e02b904",
              "IPY_MODEL_bae28680287f4a7194d524eadfa32ab5"
            ],
            "layout": "IPY_MODEL_856264b1ab3a475aa1fdc533f0d78daa"
          }
        },
        "6c4d39d95ed3418587525fd191585e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0b0acb2651d4a898f9da8313afce00e",
            "placeholder": "​",
            "style": "IPY_MODEL_58018eef766944499a284c76398a5c41",
            "value": "Extracting: 100%"
          }
        },
        "350798f012bd4dfebc6090be7e02b904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1599d7d484194378bf61ffdb6c86ac54",
            "max": 2121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4966f6c1ae245898b23dadc8751e4d8",
            "value": 2121
          }
        },
        "bae28680287f4a7194d524eadfa32ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b7a0c169bf14607b6a5957a1e51642c",
            "placeholder": "​",
            "style": "IPY_MODEL_4b2be930d2784fe2876a331d824ee071",
            "value": ""
          }
        },
        "856264b1ab3a475aa1fdc533f0d78daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b0acb2651d4a898f9da8313afce00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58018eef766944499a284c76398a5c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1599d7d484194378bf61ffdb6c86ac54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4966f6c1ae245898b23dadc8751e4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b7a0c169bf14607b6a5957a1e51642c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "2px 0 0 10px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2be930d2784fe2876a331d824ee071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}